{
  "files": [
    {
      "path": "setup.py",
      "language": "Python",
      "description": "Setup file for Quran Secrets package. Contains configuration details for packaging and installation of the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "requirements.txt",
      "language": "None",
      "description": "List of python package dependencies required by the Quran Secrets application. Contains camel_tools package.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/__init__.py",
      "language": "Python",
      "description": "Initialization file for quran_secrets package, used to mark the src directory as a Python package and perform any package-level initializations if required.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/main.py",
      "language": "python",
      "description": "Main driver for the Quran Secrets application. Orchestrates file reading, preprocessing, analysis, logging, and report generation.",
      "classes": [],
      "functions": [
        {
          "name": "main",
          "description": "Main entry point for the Quran Secrets analysis. Reads the Quran text, preprocesses it, invokes analytical functions, logs results, and writes the final report.",
          "parameters": [],
          "return_type": "None"
        }
      ],
      "dependencies": [
        "src.file_reader",
        "src.text_preprocessor",
        "src.analyzer",
        "src.logger"
      ]
    },
    {
      "path": "src/file_reader.py",
      "language": "Python",
      "description": "Module for reading the Quran text from a file. Contains a function to open a file and return its contents, or raise an IOError if the file cannot be read.",
      "classes": [],
      "functions": [
        {
          "name": "read_quran_text",
          "description": "Read and return the text from the specified Quran file. Raises an IOError if the file cannot be read.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the Quran text file."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": []
    },
    {
      "path": "src/text_preprocessor.py",
      "language": "Python",
      "description": "This module provides functionality for preprocessing and normalizing Arabic text. It includes functions to remove diacritics and normalize specific Arabic letters according to certain rules. The module is designed to standardize Arabic text for further processing in NLP or text analysis applications.",
      "classes": [],
      "functions": [
        {
          "name": "remove_diacritics",
          "description": "Removes all Arabic diacritical marks (tashkeel) from the input text. These marks include fatha, kasra, damma, sukun, shadda, and other vowel marks that appear above or below letters in Arabic script. The function uses regular expressions to identify and remove these marks.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The original Arabic text containing diacritics that need to be removed."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "normalize_arabic_letters",
          "description": "Normalizes specific Arabic letters in the given text according to contextual rules. It specifically handles two cases: 1) Converting the Arabic letter 'ى' (alef maqsura, U+0649) to 'ي' (yeh, U+064A) only when it appears as a standalone word, and 2) Converting the Arabic letter 'ة' (teh marbuta, U+0629) to 'ه' (heh, U+0647) when it appears at the end of words. This normalization helps standardize text variations that are semantically equivalent in Arabic.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The Arabic text to be normalized."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": [
        "re"
      ]
    },
    {
      "path": "src/analyzer.py",
      "language": "python",
      "description": "Module for analyzing the Quran text for hidden patterns and anomalies. This module contains various functions to perform different types of analysis on the Quran text, including numerical pattern detection, word frequency analysis, root word analysis, bigram analysis, verse repetition analysis, lemma analysis, surah and verse count analysis, verse length distribution analysis, palindrome analysis, Abjad numeral analysis, semantic symmetry analysis, Muqatta'at analysis, and comparative analysis between Surahs with and without Muqatta'at. The module aims to uncover hidden patterns and potential secrets within the Quranic text through computational linguistics and statistical methods.",
      "classes": [],
      "functions": [
        {
          "name": "analyze_text",
          "description": "Analyze the given text for hidden numerical patterns and anomalies. This function simulates pattern detection. If the text is non-empty, a simulated anomaly is detected and returned.\n\nArgs:\n    text (str): The preprocessed text of the Quran.\n\nReturns:\n    list: A list of anomaly messages detected in the text.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed text of the Quran."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_word_frequency",
          "description": "Perform word frequency analysis on the given preprocessed Quran text.\n\nThis function tokenizes the text using whitespace, counts the occurrences of each unique word,\nand determines the top N most frequent words. It prepares a summary of the word frequency analysis\nand identifies any words whose frequency is unusually high or low based on a simple heuristic.\n\nThe heuristic flags a word if its frequency is more than twice the average frequency of the top words\n(and greater than 1), or if the frequency is less than half the average (provided the average is greater than 1).\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    tuple: A tuple containing:\n        - summary (str): A formatted multiline string listing the top N words and their counts.\n        - flagged (list): A list of flagged messages for words deemed unusual.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_root_words",
          "description": "Perform Arabic root word analysis on the given preprocessed Quran text.\n\nThis function uses the CAMeL Tools morphological analyzer to extract the root of each word in the text.\nIt counts the frequency of each identified root word and logs a concise summary of the analysis to the results log file.\nSpecifically, the function logs a summary of the Arabic root word frequency analysis along with the top N most frequent root words.\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    tuple: A tuple containing:\n        - summary (str): A formatted summary of the root word frequency analysis.\n        - root_freq (dict): A dictionary mapping each root word to its frequency.\n        - top_roots (list): A list of tuples for the top N most frequent root words (root, frequency).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_bigrams",
          "description": "Perform bigram frequency analysis on the given tokenized text.\n\nThis function generates n-grams (bigrams by default) from the tokenized text,\ncounts the frequency of each n-gram, and returns a dictionary where keys are n-gram tuples\nand values are their frequency counts.\n\nArgs:\n    tokenized_text (list): A list of preprocessed tokens from the Quran text.\n    n (int): The number of words in each n-gram (default is 2 for bigrams).\n\nReturns:\n    dict: A dictionary with n-gram tuples as keys and their frequency counts as values.",
          "parameters": [
            {
              "name": "tokenized_text",
              "type": "list",
              "description": "A list of preprocessed tokens from the Quran text."
            },
            {
              "name": "n",
              "type": "int",
              "description": "The number of words in each n-gram (default is 2 for bigrams)."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_verse_repetitions",
          "description": "Analyze verse repetitions within each Surah and across the entire Quran.\n\nThis function expects the preprocessed Quran text as input where each line represents a verse.\nIt attempts to parse each line for Surah and Ayah numbers in formats such as \"Surah:Ayah: verse text\"\nor \"Surah - Ayah - verse text\", allowing for variations in spacing and delimiters.\nIf the format is not found, the verse is assigned to a default Surah \"1\" with sequential Ayah numbers.\n\nThe verse text is normalized using the existing text preprocessing functions before comparison.\nIt then identifies verses that are repeated within each Surah and across the entire Quran.\n\nReturns a dictionary with two keys:\n    \"within_surah\": A list of dictionaries each with keys: \"surah\", \"verse\", \"ayah_numbers\", \"repetition\"\n    \"across_quran\": A list of dictionaries each with keys: \"verse\", \"occurrences\" (list of {\"surah\", \"ayah\"}), \"repetition\"\n\nArgs:\n    preprocessed_text (str): The preprocessed Quran text data.\n\nReturns:\n    dict: The analysis result of verse repetitions.",
          "parameters": [
            {
              "name": "preprocessed_text",
              "type": "str",
              "description": "The preprocessed Quran text data."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_lemmas",
          "description": "Perform lemma analysis on the tokenized Quran text using CAMeL Tools morphological analyzer.\n\nThis function iterates through each word in the text, extracts its lemma using the CAMeL Tools library,\ncounts the frequency of each lemma across the entire Quran, logs the top 20 most frequent lemmas, and returns the summary.\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    str: A formatted summary of the lemma frequency analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_surah_verse_counts",
          "description": "Perform analysis of verse counts per Surah in the Quran text.\n\nThis function parses each line of the Quran text, extracts the Surah number, counts the number of verses per Surah,\nlogs the verse counts for each Surah, and returns a formatted summary.\n\nArgs:\n    text (str): The Quran text loaded from the data file.\n\nReturns:\n    str: A formatted summary of the surah verse counts.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The Quran text loaded from the data file."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_verse_lengths_distribution",
          "description": "Analyze verse lengths distribution across the Quran text.\n\nThis function calculates the word count for each verse by tokenizing the verse text,\ngroups the counts by Surah, and computes the average verse length and standard deviation\nof verse lengths for each Surah. It identifies Surahs with 'consistent' verse lengths when the standard\ndeviation is less than the threshold (default is 2 words). The summary for each Surah is logged, and\nconsistent Surahs are flagged with a special \"POTENTIAL SECRET FOUND\" log entry.\n\nArgs:\n    text (str): The preprocessed Quran text, where each line represents a verse.\n    threshold (float, optional): The standard deviation threshold to consider a Surah as having consistent verse lengths.\n    \nReturns:\n    dict: A dictionary mapping Surah numbers to a dictionary with keys 'average', 'stddev', and 'consistent'.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, where each line represents a verse."
            },
            {
              "name": "threshold",
              "type": "float, optional",
              "description": "The standard deviation threshold to consider a Surah as having consistent verse lengths."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_palindromes",
          "description": "Analyze palindromic structures within each verse of the Quran.\n\nThis function identifies word-level palindromes. It parses each verse to extract Surah and Ayah information.\nDetected palindromic words and phrases are logged to the results log in a specified format.\n\nArgs:\n    quran_text (str): The preprocessed Quran text.\n\nReturns:\n    list: A list of tuples containing (surah, ayah, palindrome_text) for each detected palindrome.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_abjad_numerals",
          "description": "Perform Abjad numeral analysis on the Quran text.\n\nThis function calculates the Abjad numerical sum for each verse based on a mapping of Arabic letters to their numerical values.\nIt logs each verse along with its calculated Abjad value. Additionally, if a verse's Abjad value meets specific criteria\n(multiple of 19, multiple of 7, or prime), it logs a special pattern message.\n\nArgs:\n    quran_text (str): The preprocessed Quran text.\n\nReturns:\n    list: A list of tuples containing (surah, ayah, abjad_sum, pattern_description) for verses with notable numerical patterns.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_semantic_symmetry",
          "description": "Analyze semantic symmetry (word overlap) between segments of each Surah.\n\nFor each Surah, this function divides the text into two roughly equal halves based on verses.\nIt then tokenizes both halves and calculates the number of common words between them.\nThe common word count is logged to the results log.\n\nArgs:\n    quran_text (str): The preprocessed Quran text.\n\nReturns:\n    list: A list of tuples containing (surah, common_word_count, list_of_common_words) for each Surah.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_verse_length_symmetry",
          "description": "Analyze verse length symmetry between two halves of each Surah.\n\nFor each Surah in the text, divided by line, the verses are split into two halves.\nThe average verse length (word count) and standard deviation of verse lengths is computed for each half.\nIf the difference in averages and standard deviations between the halves is within the given thresholds,\nthe symmetry is considered significant and logged as a potential secret.\n\nArgs:\n    text (str): The preprocessed Quran text, with each line representing a verse.\n    avg_threshold (float, optional): Maximum allowed difference in average verse length between halves.\n    stddev_threshold (float, optional): Maximum allowed difference in verse length standard deviation between halves.\n\nReturns:\n    dict: A mapping from Surah numbers to a dictionary with metrics for both halves and a symmetry flag.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, with each line representing a verse."
            },
            {
              "name": "avg_threshold",
              "type": "float, optional",
              "description": "Maximum allowed difference in average verse length between halves."
            },
            {
              "name": "stddev_threshold",
              "type": "float, optional",
              "description": "Maximum allowed difference in verse length standard deviation between halves."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_enhanced_semantic_symmetry",
          "description": "Enhanced analysis of semantic symmetry using lemma overlap between two halves of each Surah.\n\nFor each Surah, the verses are split into two halves and their texts are processed to extract lemmas.\nThe symmetry score is defined as the ratio of the number of common lemmas to the total unique lemmas in the Surah.\nIf the symmetry score meets or exceeds the threshold, it is logged as a potential secret.\n\nArgs:\n    text (str): The preprocessed Quran text, with each line representing a verse.\n    symmetry_threshold (float, optional): The minimum normalized overlap required to consider semantic symmetry.\n\nReturns:\n    dict: A mapping from Surah numbers to a dictionary with the symmetry score and lemma sets for each half.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, with each line representing a verse."
            },
            {
              "name": "symmetry_threshold",
              "type": "float, optional",
              "description": "The minimum normalized overlap required to consider semantic symmetry."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_muqattaat",
          "description": "Analyze Muqatta'at (Mysterious Letters) in the Quran text.\n\nThis function identifies Surahs that begin with Muqatta'at based on a predefined list.\nIt extracts the sequence of Arabic letters (Muqatta'at) from the beginning of the first verse of each identified Surah,\ncomputes the frequency of each unique letter, and logs the results to the results log file.\n\nThe logged output includes:\n    - A header \"#################### Muqatta'at Analysis ####################\"\n    - List of Surahs with Muqatta'at (by Surah number)\n    - For each identified Surah, the extracted Muqatta'at letters along with its Surah name.\n    - Frequency count of each unique Muqatta'at letter.\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    tuple: A tuple containing:\n        - A dictionary mapping Surah numbers to their extracted Muqatta'at letters.\n        - A Counter object representing the frequency of each Muqatta'at letter.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_muqattaat_positions",
          "description": "Analyze the positional distribution of Muqatta'at within Surahs.\n\nThis function processes the preprocessed Quran text (with each line representing a verse in the format \"Surah|Ayah|Verse\")\nto identify the occurrence positions of Muqatta'at within each Surah (only for predefined Surahs).\nIt determines in which category (Beginning, Middle, End, or Throughout) the Muqatta'at appear,\nbased on the index of the verses in the Surah where they are found. The results,\nincluding a summary count for each category, are logged to results.log.\n    \nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    str: A summary report of the Muqatta'at positional analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_muqattaat_sequences",
          "description": "Analyze Muqatta'at sequences in the Quran text.\n\nThis function identifies lines from Surahs recognized to contain Muqatta'at by checking if the Surah number is in a predefined list.\nFor each such line, it extracts the sequence of Muqatta'at letters from the beginning of the verse.\nIt then counts the frequency of each unique sequence across all such verses and returns the result.\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    dict: A dictionary mapping each unique Muqatta'at sequence (str) to its frequency (int).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_muqattaat_numerical_values",
          "description": "Perform numerical analysis of Muqatta'at using Abjad values.\n\nThis function identifies Surahs with Muqatta'at (extracted from the beginning of the first verse)\nand calculates the numerical sum of the Abjad values for each letter in the Muqatta'at.\nThe result is logged in a structured format including:\n    - Surah Number\n    - Muqatta'at Letters (as a string)\n    - Individual Abjad values for each letter\n    - Total Abjad Sum\n\nIf the total Abjad sum is a prime number, a multiple of 19, or a multiple of 7, the result is flagged\nas a potential secret.\n    \nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    str: A summary report of the Muqatta'at numerical analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_muqattaat_themes",
          "description": "Perform thematic analysis for Surahs with Muqatta'at by associating each Surah with a predefined theme.\n\nThis function iterates over a static dictionary of high-level themes for Surahs known to contain Muqatta'at.\nFor each Surah, it retrieves a hardcoded Muqatta'at letter sequence (assumed to be \"الم\") and logs a message in a\nclear, readable format to the results log.",
          "parameters": [],
          "return_type": "None"
        },
        {
          "name": "analyze_muqattaat_context",
          "description": "Analyze the verses that immediately follow the Muqatta'at in Surahs that begin with them.\n\nThis function processes the preprocessed Quran text to group verses by Surah,\nidentifies Surahs that begin with Muqatta'at (using a predefined list),\nand for each such Surah, extracts the verse immediately following the first verse (which contains the Muqatta'at).\nThe context verse is then preprocessed using existing text normalization and tokenization functions,\nand the word frequencies across all context verses are calculated.\nThe top 10 most frequent words are logged to the results log file, with any words that are unusually frequent flagged.\n\nArgs:\n    text (str): The preprocessed Quran text.\n\nReturns:\n    dict: A dictionary mapping words to their frequency counts from the context verses.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "categorize_surahs_by_muqattaat",
          "description": "Categorize Surahs into those with and without Muqatta'at.\n    \nThis function parses the preprocessed Quran text, extracts Surah numbers from each line,\nand uses the existing analyze_muqattaat() function to identify Surahs that begin with Muqatta'at.\n    \nArgs:\n    text (str): The preprocessed Quran text.\n    \nReturns:\n    tuple: A tuple containing two lists:\n        - muqattaat_surahs: List of Surah numbers (str) with Muqatta'at.\n        - non_muqattaat_surahs: List of Surah numbers (str) without Muqatta'at.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "compare_surahs_muqattaat_vs_non_muqattaat",
          "description": "Compare Surahs with and without Muqatta'at, computing average verse lengths and top word frequencies.\n    \nThis function categorizes the Surahs into those with Muqatta'at and those without,\ncomputes the average verse lengths and the top 10 most frequent words in each category,\nand returns a dictionary containing the comparisons.\n    \nArgs:\n    text (str): The preprocessed Quran text.\n        \nReturns:\n    dict: A dictionary with keys:\n        'muqattaat_surahs': list of Surah numbers with Muqatta'at,\n        'non_muqattaat_surahs': list of Surah numbers without Muqatta'at,\n        'avg_verse_length_muq': average verse length (words) for Muqatta'at Surahs,\n        'avg_verse_length_non_muq': average verse length for non-Muqatta'at Surahs,\n        'top_words_muq': list of tuples (word, frequency) for the top 10 words in Muqatta'at Surahs,\n        'top_words_non_muq': list of tuples (word, frequency) for the top 10 words in non-Muqatta'at Surahs.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_correlations",
          "description": "Analyze correlations across different analytical dimensions.\n\nThis is a stub implementation.\n    \nArgs:\n    text (str): The preprocessed Quran text.\n    verse_lengths (dict): Results from verse length analysis.\n    muqattaat_data (dict): Results from Muqatta'at analysis.\n    word_frequency_result (tuple): Results from word frequency analysis.\n    flagged_words (list): Flagged words from frequency analysis.\n    verse_repetitions_data (dict): Results from verse repetitions analysis.\n    enhanced_symmetry_data (dict): Results from enhanced semantic symmetry analysis.\n    abjad_anomalies (list): Results from Abjad numeral analysis.\n\nReturns:\n    list: A list of correlation messages (currently empty).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "verse_lengths",
              "type": "dict",
              "description": "Results from verse length analysis."
            },
            {
              "name": "muqattaat_data",
              "type": "dict",
              "description": "Results from Muqatta'at analysis."
            },
            {
              "name": "word_frequency_result",
              "type": "tuple",
              "description": "Results from word frequency analysis."
            },
            {
              "name": "flagged_words",
              "type": "list",
              "description": "Flagged words from frequency analysis."
            },
            {
              "name": "verse_repetitions_data",
              "type": "dict",
              "description": "Results from verse repetitions analysis."
            },
            {
              "name": "enhanced_symmetry_data",
              "type": "dict",
              "description": "Results from enhanced semantic symmetry analysis."
            },
            {
              "name": "abjad_anomalies",
              "type": "list",
              "description": "Results from Abjad numeral analysis."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_muqattaat_distribution_meccan_medinan",
          "description": "Analyze the distribution of Muqatta'at in Meccan versus Medinan Surahs.\n\nThis function processes the Quran text to identify Surahs that begin with Muqatta'at.\nIt then uses the provided surah_classification dictionary to count:\n  - Total number of Meccan Surahs.\n  - Total number of Medinan Surahs.\n  - Number of Meccan Surahs with Muqatta'at.\n  - Number of Medinan Surahs with Muqatta'at.\nProportions are calculated and logged, and if the difference in proportions exceeds 10%,\na potential secret is flagged.\n\nArgs:\n    text (str): The preprocessed Quran text.\n    surah_classification (dict): Dictionary mapping Surah numbers (int) to 'Meccan' or 'Medinan'.\n\nReturns:\n    None",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "surah_classification",
              "type": "dict",
              "description": "Dictionary mapping Surah numbers (int) to 'Meccan' or 'Medinan'."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "analyze_grouped_root_frequencies",
          "description": "Analyze root word frequencies for a group of Surahs.\n\nArgs:\n    text (str): The preprocessed Quran text.\n    surah_list (list): List of surah numbers to include in the analysis.\n\nReturns:\n    dict: Dictionary of root word frequencies.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "surah_list",
              "type": "list",
              "description": "List of surah numbers to include in the analysis."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_grouped_lemma_frequencies",
          "description": "Analyze lemma frequencies for a group of Surahs.\n\nArgs:\n    text (str): The preprocessed Quran text.\n    surah_list (list): List of surah numbers to include in the analysis.\n\nReturns:\n    dict: Dictionary of lemma frequencies.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "surah_list",
              "type": "list",
              "description": "List of surah numbers to include in the analysis."
            }
          ],
          "return_type": "dict"
        }
      ],
      "dependencies": [
        "collections",
        "datetime",
        "importlib.util",
        "re",
        "math",
        "src.logger",
        "src.text_preprocessor"
      ]
    },
    {
      "path": "src/logger.py",
      "language": "python",
      "description": "Module for logging analysis outputs of the Quran Secrets application. Provides functions to log secret findings, results, and bigram frequencies into a log file with timestamps.",
      "classes": [],
      "functions": [
        {
          "name": "log_secret_found",
          "description": "Logs a secret finding to the results.log file with a special tag and a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The secret message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_result",
          "description": "Logs a result message to the results.log file with a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The result message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_bigram_frequencies",
          "description": "Logs the top N most frequent bigrams to the results log file including header and frequency counts for the top N bigrams.",
          "parameters": [
            {
              "name": "bigram_frequencies",
              "type": "dict",
              "description": "A dictionary mapping bigram tuples to frequency counts."
            },
            {
              "name": "top_n",
              "type": "int",
              "description": "The number of top bigrams to log (default is 20)."
            }
          ],
          "return_type": "None"
        }
      ],
      "dependencies": []
    },
    {
      "path": "tests/__init__.py",
      "language": "Python",
      "description": "Initialization file for tests directory to mark it as a package and perform any necessary test setup.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "tests/test_file_reader.py",
      "language": "Python",
      "description": "Unit tests for the file_reader module that test reading an existing file and handling errors for non-existing files.",
      "classes": [
        {
          "name": "TestFileReader",
          "description": "Unit test class for testing the file_reader module including tests for reading existing files and error handling when files do not exist.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_read_existing_file",
              "description": "Test reading an existing file returns correct content.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_read_non_existing_file",
              "description": "Test that reading a non-existing file raises an IOError.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/file_reader.py"
      ]
    },
    {
      "path": "tests/test_text_preprocessor.py",
      "language": "Python",
      "description": "Unit tests for the text_preprocessor module testing the removal of diacritics and normalization of Arabic letters.",
      "classes": [
        {
          "name": "TestTextPreprocessor",
          "description": "Unit test class for the text_preprocessor module, ensuring proper functionality of diacritics removal and Arabic letter normalization.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_remove_diacritics",
              "description": "Test removal of Arabic diacritics from text.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_normalize_arabic_letters",
              "description": "Test normalization of specific Arabic letters in text.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/text_preprocessor.py"
      ]
    },
    {
      "path": "tests/test_analyzer.py",
      "language": "Python",
      "description": "Unit tests for the analyzer module. This file contains the TestAnalyzer class that implements various unit tests for the functions in src.analyzer.",
      "classes": [
        {
          "name": "TestAnalyzer",
          "description": "A unittest.TestCase class containing unit tests for various functions in the src.analyzer module.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Setup test environment before each test.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_non_empty",
              "description": "Test that a non-empty text returns a simulated anomaly.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_empty",
              "description": "Test that an empty text returns no anomalies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_summary",
              "description": "Test that the word frequency analysis returns a proper summary and flagged list.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_with_flags",
              "description": "Test that the word frequency analysis flags unusual word frequencies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_empty",
              "description": "Test Arabic root word analysis on empty text.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_sample",
              "description": "Test Arabic root word analysis on sample text with mocked CAMeL Tools analyzer.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_empty",
              "description": "Test that analyze_bigrams returns an empty dictionary when provided an empty tokenized text or insufficient tokens.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_sample",
              "description": "Test analyze_bigrams with a sample tokenized text for correct bigram generation and frequency counting.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_palindromes_detects_palindrome",
              "description": "Test that analyze_palindromes detects palindromic words and phrases.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_abjad_numerals_detects_patterns",
              "description": "Test that analyze_abjad_numerals detects notable numerical patterns.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_semantic_symmetry_detects_symmetry",
              "description": "Test that analyze_semantic_symmetry detects significant word overlap.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_repetitions",
              "description": "Test that analyze_verse_repetitions correctly identifies repetitions both intra-surah and across the Quran.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_lengths_distribution",
              "description": "Test that analyze_verse_lengths_distribution correctly calculates average verse length, standard deviation, and identifies consistent surahs.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_length_symmetry_symmetry_detected",
              "description": "Test that analyze_verse_length_symmetry detects symmetry when halves have similar verse lengths.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_length_symmetry_non_symmetric",
              "description": "Test that analyze_verse_length_symmetry returns non-symmetric when verse lengths differ significantly.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_enhanced_semantic_symmetry_symmetry_detected",
              "description": "Test that analyze_enhanced_semantic_symmetry detects semantic symmetry when lemma overlap is high.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_enhanced_semantic_symmetry_low_symmetry",
              "description": "Test that analyze_enhanced_semantic_symmetry returns low symmetry score when lemma overlap is minimal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src.analyzer",
        "src.logger",
        "unittest",
        "unittest.mock"
      ]
    },
    {
      "path": "tests/test_logger.py",
      "language": "Python",
      "description": "This file contains unit tests for the logger module. It tests the functionality of logging secret findings and general results. The tests use unittest framework with mocking to isolate the tests from actual file operations and datetime dependencies.",
      "classes": [
        {
          "name": "TestLogger",
          "description": "A test class that contains test cases for the logger module. It verifies that the logging functions correctly format and write messages to the log file.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Initializes the test environment by setting maxDiff to None to see full diff output in case of test failures.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_log_secret_found",
              "description": "Tests that the log_secret_found function correctly formats and writes a message about a potential secret to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_log_result",
              "description": "Tests that the log_result function correctly formats and writes a general result message to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "unittest",
        "os",
        "unittest.mock",
        "src.logger"
      ]
    },
    {
      "path": "tests/test_main.py",
      "language": "python",
      "description": "Integration test for the main module to execute end-to-end analysis. This test suite includes integration tests for the main module of the Quran Secrets application. It focuses on testing the end-to-end execution of the analysis pipeline, ensuring that all components work together correctly. Test cases cover scenarios with and without CAMeL Tools availability, and also include specific tests for comparative analysis functions. The suite aims to validate the overall functionality and robustness of the application in an integrated environment.",
      "classes": [
        {
          "name": "TestMainIntegration",
          "description": "Test cases for end-to-end integration of the Quran Secrets application.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Set maximum diff for assertions.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_fallback",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools fallback.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_with_camel_tools",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools available.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_compare_surahs_muqattaat_vs_non_muqattaat",
              "description": "Test the compare_surahs_muqattaat_vs_non_muqattaat() function for correct categorization and analysis.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "os",
        "unittest",
        "unittest.mock",
        "importlib.util",
        "src.main"
      ]
    },
    {
      "path": "data/quran-uthmani-min.txt",
      "language": "None",
      "description": "Text file containing the Quran text. This file is used as input for the analysis performed by the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    }
  ]
}