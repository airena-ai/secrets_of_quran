{
  "files": [
    {
      "path": "setup.py",
      "language": "Python",
      "description": "Setup file for Quran Secrets package. Contains configuration details for packaging and installation of the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "requirements.txt",
      "language": "None",
      "description": "List of python package dependencies required by the Quran Secrets application. Contains camel_tools package.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/__init__.py",
      "language": "Python",
      "description": "Initialization file for quran_secrets package, used to mark the src directory as a Python package and perform any package-level initializations if required.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/main.py",
      "language": "Python",
      "description": "Main driver for the Quran Secrets application. It orchestrates the reading of Quran text, preprocessing, and various analytical functions including verse length analysis, word frequency analysis, Arabic root word extraction, bigram analysis, palindrome detection, and Muqatta'at evaluations. It logs results and writes a final report.",
      "classes": [],
      "functions": [
        {
          "name": "main",
          "description": "Main entry point for the Quran Secrets analysis. It reads the Quran text, applies preprocessing, performs multiple analyses, logs results, and writes out a final report.",
          "parameters": [],
          "return_type": "None"
        }
      ],
      "dependencies": [
        "src/file_reader.py",
        "src/text_preprocessor.py",
        "src/analyzer.py",
        "src/logger.py"
      ]
    },
    {
      "path": "src/file_reader.py",
      "language": "Python",
      "description": "Module for reading the Quran text from a file. Contains a function to open a file and return its contents, or raise an IOError if the file cannot be read.",
      "classes": [],
      "functions": [
        {
          "name": "read_quran_text",
          "description": "Read and return the text from the specified Quran file. Raises an IOError if the file cannot be read.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the Quran text file."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": []
    },
    {
      "path": "src/text_preprocessor.py",
      "language": "Python",
      "description": "This module provides functionality for preprocessing and normalizing Arabic text. It includes functions to remove diacritics and normalize specific Arabic letters according to certain rules. The module is designed to standardize Arabic text for further processing in NLP or text analysis applications.",
      "classes": [],
      "functions": [
        {
          "name": "remove_diacritics",
          "description": "Removes all Arabic diacritical marks (tashkeel) from the input text. These marks include fatha, kasra, damma, sukun, shadda, and other vowel marks that appear above or below letters in Arabic script. The function uses regular expressions to identify and remove these marks.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The original Arabic text containing diacritics that need to be removed."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "normalize_arabic_letters",
          "description": "Normalizes specific Arabic letters in the given text according to contextual rules. It specifically handles two cases: 1) Converting the Arabic letter 'ى' (alef maqsura, U+0649) to 'ي' (yeh, U+064A) only when it appears as a standalone word, and 2) Converting the Arabic letter 'ة' (teh marbuta, U+0629) to 'ه' (heh, U+0647) when it appears at the end of words. This normalization helps standardize text variations that are semantically equivalent in Arabic.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The Arabic text to be normalized."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": [
        "re"
      ]
    },
    {
      "path": "src/analyzer.py",
      "language": "python",
      "description": "Module for analyzing the Quran text for hidden patterns and anomalies.",
      "classes": [],
      "functions": [
        {
          "name": "analyze_text",
          "description": "Analyze the given text for hidden numerical patterns and anomalies.\n\n    This function simulates pattern detection. If the text is non-empty,\n    a simulated anomaly is detected and returned.\n\n    Args:\n        text (str): The preprocessed text of the Quran.\n\n    Returns:\n        list: A list of anomaly messages detected in the text.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed text of the Quran."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_word_frequency",
          "description": "Perform word frequency analysis on the given preprocessed Quran text.\n\n    This function tokenizes the text using whitespace, counts the occurrences of each unique word,\n    and determines the top N most frequent words. It prepares a summary of the word frequency analysis\n    and identifies any words whose frequency is unusually high or low based on a simple heuristic.\n\n    The heuristic flags a word if its frequency is more than twice the average frequency of the top words\n    (and greater than 1), or if the frequency is less than half the average (provided the average is greater than 1).\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        tuple: A tuple containing:\n            - summary (str): A formatted multiline string listing the top N words and their counts.\n            - flagged (list): A list of flagged messages for words deemed unusual.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_root_words",
          "description": "Perform Arabic root word analysis on the given preprocessed Quran text.\n\n    This function uses the CAMeL Tools morphological analyzer to extract the root of each word in the text.\n    It counts the frequency of each identified root word and logs a concise summary of the analysis to the results log file.\n    Specifically, the function logs a summary of the Arabic root word frequency analysis along with the top N most frequent root words.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        tuple: A tuple containing:\n            - summary (str): A formatted summary of the root word frequency analysis.\n            - root_freq (dict): A dictionary mapping each root word to its frequency.\n            - top_roots (list): A list of tuples for the top N most frequent root words (root, frequency).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_bigrams",
          "description": "Perform bigram frequency analysis on the given tokenized text.\n\n    This function generates n-grams (bigrams by default) from the tokenized text,\n    counts the frequency of each n-gram, and returns a dictionary where keys are n-gram tuples\n    and values are their frequency counts.\n\n    Args:\n        tokenized_text (list): A list of preprocessed tokens from the Quran text.\n        n (int): The number of words in each n-gram (default is 2 for bigrams).\n\n    Returns:\n        dict: A dictionary with n-gram tuples as keys and their frequency counts as values.",
          "parameters": [
            {
              "name": "tokenized_text",
              "type": "list",
              "description": "A list of preprocessed tokens from the Quran text."
            },
            {
              "name": "n",
              "type": "int",
              "description": "The number of words in each n-gram (default is 2 for bigrams)."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_verse_repetitions",
          "description": "Analyze verse repetitions within each Surah and across the entire Quran.\n    \n    This function expects the preprocessed Quran text as input where each line represents a verse.\n    It attempts to parse each line for Surah and Ayah numbers in formats such as \"Surah:Ayah: verse text\"\n    or \"Surah - Ayah - verse text\", allowing for variations in spacing and delimiters.\n    If the format is not found, the verse is assigned to a default Surah \"1\" with sequential Ayah numbers.\n    \n    The verse text is normalized using the existing text preprocessing functions before comparison.\n    It then identifies verses that are repeated within each Surah and across the entire Quran.\n    \n    Returns a dictionary with two keys:\n        \"within_surah\": A list of dictionaries each with keys: \"surah\", \"verse\", \"ayah_numbers\", \"repetition\"\n        \"across_quran\": A list of dictionaries each with keys: \"verse\", \"occurrences\" (list of {\"surah\", \"ayah\"}), \"repetition\"\n    \n    Args:\n        preprocessed_text (str): The preprocessed Quran text data.\n    \n    Returns:\n        dict: The analysis result of verse repetitions.",
          "parameters": [
            {
              "name": "preprocessed_text",
              "type": "str",
              "description": "The preprocessed Quran text data."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_lemmas",
          "description": "Perform lemma analysis on the tokenized Quran text using CAMeL Tools morphological analyzer.\n    \n    This function iterates through each word in the text, extracts its lemma using the CAMeL Tools library,\n    counts the frequency of each lemma across the entire Quran, logs the top 20 most frequent lemmas, and returns the summary.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        str: A formatted summary of the lemma frequency analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_surah_verse_counts",
          "description": "Perform analysis of verse counts per Surah in the Quran text.\n    \n    This function parses each line of the Quran text, extracts the Surah number, counts the number of verses per Surah,\n    logs the verse counts for each Surah, and returns a formatted summary.\n\n    Args:\n        text (str): The Quran text loaded from the data file.\n\n    Returns:\n        str: A formatted summary of the surah verse counts.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The Quran text loaded from the data file."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_verse_lengths_distribution",
          "description": "Analyze verse lengths distribution across the Quran text.\n    \n    This function calculates the word count for each verse by tokenizing the verse text,\n    groups the counts by Surah, and computes the average verse length and standard deviation\n    of verse lengths for each Surah. It identifies Surahs with 'consistent' verse lengths when the standard\n    deviation is less than the threshold (default is 2 words). The summary for each Surah is logged, and\n    consistent Surahs are flagged with a special \"POTENTIAL SECRET FOUND\" log entry.\n    \n    Args:\n        text (str): The preprocessed Quran text, where each line represents a verse.\n        threshold (float, optional): The standard deviation threshold to consider a Surah as having consistent verse lengths.\n        \n    Returns:\n        dict: A dictionary mapping Surah numbers to a dictionary with keys 'average', 'stddev', and 'consistent'.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, where each line represents a verse."
            },
            {
              "name": "threshold",
              "type": "float, optional",
              "description": "The standard deviation threshold to consider a Surah as having consistent verse lengths."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_palindromes",
          "description": "Analyze palindromic structures within each verse of the Quran.\n    \n    This function identifies word-level palindromes. It parses each verse to extract Surah and Ayah information.\n    Detected palindromic words and phrases are logged to the results log in a specified format.\n\n    Args:\n        quran_text (str): The preprocessed Quran text.\n\n    Returns:\n        list: A list of tuples containing (surah, ayah, palindrome_text) for each detected palindrome.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_abjad_numerals",
          "description": "Perform Abjad numeral analysis on the Quran text.\n    \n    This function calculates the Abjad numerical sum for each verse based on a mapping of Arabic letters to their numerical values.\n    It logs each verse along with its calculated Abjad value. Additionally, if a verse's Abjad value meets specific criteria\n    (multiple of 19, multiple of 7, or prime), it logs a special pattern message.\n\n    Args:\n        quran_text (str): The preprocessed Quran text.\n\n    Returns:\n        list: A list of tuples containing (surah, ayah, abjad_sum, pattern_description) for verses with notable numerical patterns.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_semantic_symmetry",
          "description": "Analyze semantic symmetry (word overlap) between segments of each Surah.\n    \n    For each Surah, this function divides the text into two roughly equal halves based on verses.\n    It then tokenizes both halves and calculates the number of common words between them.\n    The common word count is logged to the results log.\n\n    Args:\n        quran_text (str): The preprocessed Quran text.\n\n    Returns:\n        list: A list of tuples containing (surah, common_word_count, list_of_common_words) for each Surah.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_verse_length_symmetry",
          "description": "Analyze verse length symmetry between two halves of each Surah.\n    \n    For each Surah in the text, divided by line, the verses are split into two halves.\n    The average verse length (word count) and standard deviation of verse lengths is computed for each half.\n    If the difference in averages and standard deviations between the halves is within the given thresholds,\n    the symmetry is considered significant and logged as a potential secret.\n    \n    Args:\n        text (str): The preprocessed Quran text, with each line representing a verse.\n        avg_threshold (float, optional): Maximum allowed difference in average verse length between halves.\n        stddev_threshold (float, optional): Maximum allowed difference in verse length standard deviation between halves.\n    \n    Returns:\n        dict: A mapping from Surah numbers to a dictionary with metrics for both halves and a symmetry flag.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, with each line representing a verse."
            },
            {
              "name": "avg_threshold",
              "type": "float, optional",
              "description": "Maximum allowed difference in average verse length between halves."
            },
            {
              "name": "stddev_threshold",
              "type": "float, optional",
              "description": "Maximum allowed difference in verse length standard deviation between halves."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_enhanced_semantic_symmetry",
          "description": "Enhanced analysis of semantic symmetry using lemma overlap between two halves of each Surah.\n    \n    For each Surah, the verses are split into two halves and their texts are processed to extract lemmas.\n    The symmetry score is defined as the ratio of the number of common lemmas to the total unique lemmas in the Surah.\n    If the symmetry score meets or exceeds the threshold, it is logged as a potential secret.\n    \n    Args:\n        text (str): The preprocessed Quran text, with each line representing a verse.\n        symmetry_threshold (float, optional): The minimum normalized overlap required to consider semantic symmetry.\n    \n    Returns:\n        dict: A mapping from Surah numbers to a dictionary with the symmetry score and lemma sets for each half.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text, with each line representing a verse."
            },
            {
              "name": "symmetry_threshold",
              "type": "float, optional",
              "description": "The minimum normalized overlap required to consider semantic symmetry."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_muqattaat",
          "description": "Analyze Muqatta'at (Mysterious Letters) in the Quran text.\n\n    This function identifies Surahs that begin with Muqatta'at based on a predefined list.\n    It extracts the sequence of Arabic letters (Muqatta'at) from the beginning of the first verse of each identified Surah,\n    computes the frequency of each unique letter, and logs the results to the results log file.\n\n    The logged output includes:\n        - A header \"#################### Muqatta'at Analysis ####################\"\n        - List of Surahs with Muqatta'at (by Surah number)\n        - For each identified Surah, the extracted Muqatta'at letters along with its Surah name.\n        - Frequency count of each unique Muqatta'at letter.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        tuple: A tuple containing:\n            - A dictionary mapping Surah numbers to their extracted Muqatta'at letters.\n            - A Counter object representing the frequency of each Muqatta'at letter.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_muqattaat_positions",
          "description": "Analyze the positional distribution of Muqatta'at within Surahs.\n\n    This function processes the preprocessed Quran text (with each line representing a verse in the format \"Surah|Ayah|Verse\")\n    to identify the occurrence positions of Muqatta'at within each Surah (only for predefined Surahs).\n    It determines in which category (Beginning, Middle, End, or Throughout) the Muqatta'at appear,\n    based on the index of the verses in the Surah where they are found. The results,\n    including a summary count for each category, are logged to results.log.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        str: A summary report of the Muqatta'at positional analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_muqattaat_sequences",
          "description": "Analyze Muqatta'at sequences in the Quran text.\n\n    This function identifies lines from Surahs recognized to contain Muqatta'at by checking if the Surah number is in a predefined list.\n    For each such line, it extracts the sequence of Muqatta'at letters from the beginning of the verse.\n    It then counts the frequency of each unique sequence across all such verses and returns the result.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        dict: A dictionary mapping each unique Muqatta'at sequence (str) to its frequency (int).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_muqattaat_numerical_values",
          "description": "Perform numerical analysis of Muqatta'at using Abjad values.\n\n    This function identifies Surahs with Muqatta'at (extracted from the beginning of the first verse)\n    and calculates the numerical sum of the Abjad values for each letter in the Muqatta'at.\n    The result is logged in a structured format including:\n        - Surah Number\n        - Muqatta'at Letters (as a string)\n        - Individual Abjad values for each letter\n        - Total Abjad Sum\n\n    If the total Abjad sum is a prime number, a multiple of 19, or a multiple of 7, the result is flagged\n    as a potential secret.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        str: A summary report of the Muqatta'at numerical analysis.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "analyze_muqattaat_themes",
          "description": "Perform thematic analysis for Surahs with Muqatta'at by associating each Surah with a predefined theme.\n\n    This function iterates over a static dictionary of high-level themes for Surahs known to contain Muqatta'at.\n    For each Surah, it retrieves a hardcoded Muqatta'at letter sequence (assumed to be \"الم\") and logs a message in a\n    clear, readable format to the results log.",
          "parameters": [],
          "return_type": "None"
        },
        {
          "name": "analyze_muqattaat_context",
          "description": "Analyze the verses that immediately follow the Muqatta'at in Surahs that begin with them.\n\n    This function processes the preprocessed Quran text to group verses by Surah,\n    identifies Surahs that begin with Muqatta'at (using a predefined list),\n    and for each such Surah, extracts the verse immediately following the first verse (which contains the Muqatta'at).\n    The context verse is then preprocessed using existing text normalization and tokenization functions,\n    and the word frequencies across all context verses are calculated.\n    The top 10 most frequent words are logged to the results log file, with any words that are unusually frequent flagged.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        dict: A dictionary mapping words to their frequency counts from the context verses.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "categorize_surahs_by_muqattaat",
          "description": "Categorize Surahs into those with and without Muqatta'at.\n    \n    This function parses the preprocessed Quran text, extracts Surah numbers from each line,\n    and uses the existing analyze_muqattaat() function to identify Surahs that begin with Muqatta'at.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n    \n    Returns:\n        tuple: A tuple containing two lists:\n            - muqattaat_surahs: List of Surah numbers (str) with Muqatta'at.\n            - non_muqattaat_surahs: List of Surah numbers (str) without Muqatta'at.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "compare_surahs_muqattaat_vs_non_muqattaat",
          "description": "Compare Surahs with and without Muqatta'at, computing average verse lengths and top word frequencies.\n    \n    This function categorizes the Surahs into those with Muqatta'at and those without,\n    computes the average verse lengths and the top 10 most frequent words in each category,\n    and returns a dictionary containing the comparisons.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n        \n    Returns:\n        dict: A dictionary with keys:\n            'muqattaat_surahs': list of Surah numbers with Muqatta'at,\n            'non_muqattaat_surahs': list of Surah numbers without Muqatta'at,\n            'avg_verse_length_muq': average verse length (words) for Muqatta'at Surahs,\n            'avg_verse_length_non_muq': average verse length for non-Muqatta'at Surahs,\n            'top_words_muq': list of tuples (word, frequency) for the top 10 words in Muqatta'at Surahs,\n            'top_words_non_muq': list of tuples (word, frequency) for the top 10 words in non-Muqatta'at Surahs.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_grouped_root_frequencies",
          "description": "Aggregate Arabic root word frequencies for the specified Surahs.\n    \n    This function retrieves all verses belonging to the Surahs in the provided list,\n    concatenates their text, performs root word analysis using the existing analyze_root_words function,\n    and returns an aggregated dictionary of root word frequencies.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n        surah_list (list): List of Surah numbers (as strings) to analyze.\n    \n    Returns:\n        dict: A dictionary mapping root words to their aggregated frequencies.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "surah_list",
              "type": "list",
              "description": "List of Surah numbers (as strings) to analyze."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_grouped_lemma_frequencies",
          "description": "Aggregate lemma frequencies for the specified Surahs.\n    \n    This function retrieves all verses belonging to the given Surahs,\n    concatenates their text, performs lemma analysis by extracting lemmas for each word (using CAMeL Tools if available),\n    and returns an aggregated dictionary of lemma frequencies.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n        surah_list (list): List of Surah numbers (as strings) to analyze.\n    \n    Returns:\n        dict: A dictionary mapping lemmas to their aggregated frequencies.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "surah_list",
              "type": "list",
              "description": "List of Surah numbers (as strings) to analyze."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_correlations",
          "description": "Analyze correlations across different analytical dimensions.\n\n    This is a stub implementation.\n    \n    Args:\n        text (str): The preprocessed Quran text.\n        verse_lengths (dict): Results from verse length analysis.\n        muqattaat_data (dict): Results from Muqatta'at analysis.\n        word_frequency_result (tuple): Results from word frequency analysis.\n        flagged_words (list): Flagged words from frequency analysis.\n        verse_repetitions_data (dict): Results from verse repetitions analysis.\n        enhanced_symmetry_data (dict): Results from enhanced semantic symmetry analysis.\n        abjad_anomalies (list): Results from Abjad numeral analysis.\n\n    Returns:\n        list: A list of correlation messages (currently empty).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            },
            {
              "name": "verse_lengths",
              "type": "dict",
              "description": "Results from verse length analysis."
            },
            {
              "name": "muqattaat_data",
              "type": "dict",
              "description": "Results from Muqatta'at analysis."
            },
            {
              "name": "word_frequency_result",
              "type": "tuple",
              "description": "Results from word frequency analysis."
            },
            {
              "name": "flagged_words",
              "type": "list",
              "description": "Flagged words from frequency analysis."
            },
            {
              "name": "verse_repetitions_data",
              "type": "dict",
              "description": "Results from verse repetitions analysis."
            },
            {
              "name": "enhanced_symmetry_data",
              "type": "dict",
              "description": "Results from enhanced semantic symmetry analysis."
            },
            {
              "name": "abjad_anomalies",
              "type": "list",
              "description": "Results from Abjad numeral analysis."
            }
          ],
          "return_type": "list"
        }
      ],
      "dependencies": [
        "collections",
        "datetime",
        "importlib.util",
        "re",
        "math",
        "src.logger",
        "src.text_preprocessor"
      ]
    },
    {
      "path": "src/logger.py",
      "language": "python",
      "description": "Module for logging analysis outputs of the Quran Secrets application. Provides functions to log secret findings, results, and bigram frequencies into a log file with timestamps.",
      "classes": [],
      "functions": [
        {
          "name": "log_secret_found",
          "description": "Logs a secret finding to the results.log file with a special tag and a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The secret message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_result",
          "description": "Logs a result message to the results.log file with a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The result message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_bigram_frequencies",
          "description": "Logs the top N most frequent bigrams to the results log file including header and frequency counts for the top N bigrams.",
          "parameters": [
            {
              "name": "bigram_frequencies",
              "type": "dict",
              "description": "A dictionary mapping bigram tuples to frequency counts."
            },
            {
              "name": "top_n",
              "type": "int",
              "description": "The number of top bigrams to log (default is 20)."
            }
          ],
          "return_type": "None"
        }
      ],
      "dependencies": []
    },
    {
      "path": "tests/__init__.py",
      "language": "Python",
      "description": "Initialization file for tests directory to mark it as a package and perform any necessary test setup.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "tests/test_file_reader.py",
      "language": "Python",
      "description": "Unit tests for the file_reader module that test reading an existing file and handling errors for non-existing files.",
      "classes": [
        {
          "name": "TestFileReader",
          "description": "Unit test class for testing the file_reader module including tests for reading existing files and error handling when files do not exist.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_read_existing_file",
              "description": "Test reading an existing file returns correct content.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_read_non_existing_file",
              "description": "Test that reading a non-existing file raises an IOError.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/file_reader.py"
      ]
    },
    {
      "path": "tests/test_text_preprocessor.py",
      "language": "Python",
      "description": "Unit tests for the text_preprocessor module testing the removal of diacritics and normalization of Arabic letters.",
      "classes": [
        {
          "name": "TestTextPreprocessor",
          "description": "Unit test class for the text_preprocessor module, ensuring proper functionality of diacritics removal and Arabic letter normalization.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_remove_diacritics",
              "description": "Test removal of Arabic diacritics from text.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_normalize_arabic_letters",
              "description": "Test normalization of specific Arabic letters in text.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/text_preprocessor.py"
      ]
    },
    {
      "path": "tests/test_analyzer.py",
      "language": "Python",
      "description": "Unit tests for the analyzer module. This file contains the TestAnalyzer class that implements various unit tests for the functions in src.analyzer.",
      "classes": [
        {
          "name": "TestAnalyzer",
          "description": "A unittest.TestCase class containing unit tests for various functions in the src.analyzer module.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Setup test environment before each test.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_non_empty",
              "description": "Test that a non-empty text returns a simulated anomaly.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_empty",
              "description": "Test that an empty text returns no anomalies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_summary",
              "description": "Test that the word frequency analysis returns a proper summary and flagged list.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_with_flags",
              "description": "Test that the word frequency analysis flags unusual word frequencies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_empty",
              "description": "Test Arabic root word analysis on empty text.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_sample",
              "description": "Test Arabic root word analysis on sample text with mocked CAMeL Tools analyzer.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_empty",
              "description": "Test that analyze_bigrams returns an empty dictionary when provided an empty tokenized text or insufficient tokens.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_sample",
              "description": "Test analyze_bigrams with a sample tokenized text for correct bigram generation and frequency counting.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_palindromes_detects_palindrome",
              "description": "Test that analyze_palindromes detects palindromic words and phrases.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_abjad_numerals_detects_patterns",
              "description": "Test that analyze_abjad_numerals detects notable numerical patterns.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_semantic_symmetry_detects_symmetry",
              "description": "Test that analyze_semantic_symmetry detects significant word overlap.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_repetitions",
              "description": "Test that analyze_verse_repetitions correctly identifies repetitions both intra-surah and across the Quran.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_lengths_distribution",
              "description": "Test that analyze_verse_lengths_distribution correctly calculates average verse length, standard deviation, and identifies consistent surahs.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_length_symmetry_symmetry_detected",
              "description": "Test that analyze_verse_length_symmetry detects symmetry when halves have similar verse lengths.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_verse_length_symmetry_non_symmetric",
              "description": "Test that analyze_verse_length_symmetry returns non-symmetric when verse lengths differ significantly.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_enhanced_semantic_symmetry_symmetry_detected",
              "description": "Test that analyze_enhanced_semantic_symmetry detects semantic symmetry when lemma overlap is high.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_enhanced_semantic_symmetry_low_symmetry",
              "description": "Test that analyze_enhanced_semantic_symmetry returns low symmetry score when lemma overlap is minimal.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src.analyzer",
        "src.logger",
        "unittest",
        "unittest.mock"
      ]
    },
    {
      "path": "tests/test_logger.py",
      "language": "Python",
      "description": "This file contains unit tests for the logger module. It tests the functionality of logging secret findings and general results. The tests use unittest framework with mocking to isolate the tests from actual file operations and datetime dependencies.",
      "classes": [
        {
          "name": "TestLogger",
          "description": "A test class that contains test cases for the logger module. It verifies that the logging functions correctly format and write messages to the log file.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Initializes the test environment by setting maxDiff to None to see full diff output in case of test failures.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_log_secret_found",
              "description": "Tests that the log_secret_found function correctly formats and writes a message about a potential secret to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_log_result",
              "description": "Tests that the log_result function correctly formats and writes a general result message to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "unittest",
        "os",
        "unittest.mock",
        "src.logger"
      ]
    },
    {
      "path": "tests/test_main.py",
      "language": "python",
      "description": "Integration test for the main module to execute end-to-end analysis.",
      "classes": [
        {
          "name": "TestMainIntegration",
          "description": "Test cases for end-to-end integration of the Quran Secrets application.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Set maximum diff for assertions.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_fallback",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools fallback.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_with_camel_tools",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools available.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_compare_surahs_muqattaat_vs_non_muqattaat",
              "description": "Test the compare_surahs_muqattaat_vs_non_muqattaat() function for correct categorization and analysis.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "os",
        "unittest",
        "unittest.mock",
        "importlib.util",
        "src.main"
      ]
    },
    {
      "path": "data/quran-uthmani-min.txt",
      "language": "None",
      "description": "Text file containing the Quran text. This file is used as input for the analysis performed by the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    }
  ]
}