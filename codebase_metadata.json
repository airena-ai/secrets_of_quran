{
  "files": [
    {
      "path": "setup.py",
      "language": "Python",
      "description": "Setup file for Quran Secrets package. Contains configuration details for packaging and installation of the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "requirements.txt",
      "language": "None",
      "description": "Lists package dependencies required for the project, including camel-tools. This file is used by pip to install required packages.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/__init__.py",
      "language": "Python",
      "description": "Initialization file for quran_secrets package, used to mark the src directory as a Python package and perform any package-level initializations if required.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "src/main.py",
      "language": "python",
      "description": "Main driver for the Quran Secrets application. Coordinates file reading, text preprocessing, analysis functions, and logging to provide a complete analysis of the Quran text.",
      "classes": [],
      "functions": [
        {
          "name": "main",
          "description": "Main entry point for the Quran Secrets analysis. Reads the Quran text, applies preprocessing, performs multiple analyses, logs the results, and handles errors.",
          "parameters": [],
          "return_type": "None"
        }
      ],
      "dependencies": [
        "src/file_reader.py",
        "src/text_preprocessor.py",
        "src/analyzer.py",
        "src/logger.py"
      ]
    },
    {
      "path": "src/file_reader.py",
      "language": "Python",
      "description": "Module for reading the Quran text from a file. Contains a function to open a file and return its contents, or raise an IOError if the file cannot be read.",
      "classes": [],
      "functions": [
        {
          "name": "read_quran_text",
          "description": "Read and return the text from the specified Quran file. Raises an IOError if the file cannot be read.",
          "parameters": [
            {
              "name": "file_path",
              "type": "str",
              "description": "The path to the Quran text file."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": []
    },
    {
      "path": "src/text_preprocessor.py",
      "language": "Python",
      "description": "This module provides functionality for preprocessing and normalizing Arabic text. It includes functions to remove diacritics and normalize specific Arabic letters according to certain rules. The module is designed to standardize Arabic text for further processing in NLP or text analysis applications.",
      "classes": [],
      "functions": [
        {
          "name": "remove_diacritics",
          "description": "Removes all Arabic diacritical marks (tashkeel) from the input text. These marks include fatha, kasra, damma, sukun, shadda, and other vowel marks that appear above or below letters in Arabic script. The function uses regular expressions to identify and remove these marks.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The original Arabic text containing diacritics that need to be removed."
            }
          ],
          "return_type": "str"
        },
        {
          "name": "normalize_arabic_letters",
          "description": "Normalizes specific Arabic letters in the given text according to contextual rules. It specifically handles two cases: 1) Converting the Arabic letter 'ى' (alef maqsura, U+0649) to 'ي' (yeh, U+064A) only when it appears as a standalone word, and 2) Converting the Arabic letter 'ة' (teh marbuta, U+0629) to 'ه' (heh, U+0647) when it appears at the end of words. This normalization helps standardize text variations that are semantically equivalent in Arabic.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The Arabic text to be normalized."
            }
          ],
          "return_type": "str"
        }
      ],
      "dependencies": [
        "re"
      ]
    },
    {
      "path": "src/analyzer.py",
      "language": "python",
      "description": "Module for analyzing the Quran text for hidden patterns and anomalies. This module provides functionalities to perform various text analyses on the Quran, such as numerical pattern detection, word frequency analysis, root word analysis, bigram analysis, verse repetition analysis, palindrome analysis, Abjad numeral analysis, and semantic symmetry analysis. It is designed to identify potential hidden patterns and anomalies within the Quranic text.",
      "classes": [],
      "functions": [
        {
          "name": "analyze_text",
          "description": "Analyze the given text for hidden numerical patterns and anomalies.\n\n    This function simulates pattern detection. If the text is non-empty,\n    a simulated anomaly is detected and returned.\n\n    Args:\n        text (str): The preprocessed text of the Quran.\n\n    Returns:\n        list: A list of anomaly messages detected in the text.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed text of the Quran."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_word_frequency",
          "description": "Perform word frequency analysis on the given preprocessed Quran text.\n\n    This function tokenizes the text using whitespace, counts the occurrences of each unique word,\n    and determines the top N most frequent words. It prepares a summary of the word frequency analysis\n    and identifies any words whose frequency is unusually high or low based on a simple heuristic.\n\n    The heuristic flags a word if its frequency is more than twice the average frequency of the top words\n    (and greater than 1), or if the frequency is less than half the average (provided the average is greater than 1).\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        tuple: A tuple containing:\n            - summary (str): A formatted multiline string listing the top N words and their counts.\n            - flagged (list): A list of flagged messages for words deemed unusual.",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_root_words",
          "description": "Perform Arabic root word analysis on the given preprocessed Quran text.\n\n    This function uses the CAMeL Tools morphological analyzer to extract the root of each word in the text.\n    It counts the frequency of each identified root word and logs a concise summary of the analysis to the results log file.\n    Specifically, the function logs a summary of the Arabic root word frequency analysis along with the top N most frequent root words.\n\n    Args:\n        text (str): The preprocessed Quran text.\n\n    Returns:\n        tuple: A tuple containing:\n            - summary (str): A formatted summary of the root word frequency analysis.\n            - root_freq (dict): A dictionary mapping each root word to its frequency.\n            - top_roots (list): A list of tuples for the top N most frequent root words (root, frequency).",
          "parameters": [
            {
              "name": "text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "tuple"
        },
        {
          "name": "analyze_bigrams",
          "description": "Perform bigram frequency analysis on the given tokenized text.\n\n    This function generates n-grams (bigrams by default) from the tokenized text,\n    counts the frequency of each n-gram, and returns a dictionary where keys are n-gram tuples\n    and values are their respective occurrence counts.\n\n    Args:\n        tokenized_text (list): A list of preprocessed tokens from the Quran text.\n        n (int): The number of words in each n-gram (default is 2 for bigrams).\n\n    Returns:\n        dict: A dictionary with n-gram tuples as keys and their frequency counts as values.",
          "parameters": [
            {
              "name": "tokenized_text",
              "type": "list",
              "description": "A list of preprocessed tokens from the Quran text."
            },
            {
              "name": "n",
              "type": "int",
              "description": "The number of words in each n-gram (default is 2 for bigrams)."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_verse_repetitions",
          "description": "Analyze verse repetitions within each Surah and across the entire Quran.\n    \n    This function expects the preprocessed Quran text as input where each line represents a verse.\n    It attempts to parse each line for Surah and Ayah numbers in formats such as \"Surah:Ayah: verse text\"\n    or \"Surah - Ayah - verse text\", allowing for variations in spacing and delimiters.\n    If the format is not found, the verse is assigned to a default Surah \"1\" with sequential Ayah numbers.\n    \n    The verse text is normalized using the existing text preprocessing functions before comparison.\n    It then identifies verses that are repeated within each Surah and across the entire Quran.\n    \n    Returns a dictionary with two keys:\n        \"within_surah\": A list of dictionaries each with keys: \"surah\", \"verse\", \"ayah_numbers\", \"repetition\"\n        \"across_quran\": A list of dictionaries each with keys: \"verse\", \"occurrences\" (list of {\"surah\", \"ayah\"}), \"repetition\"\n    \n    Args:\n        preprocessed_text (str): The preprocessed Quran text data.\n    \n    Returns:\n        dict: The analysis result of verse repetitions.",
          "parameters": [
            {
              "name": "preprocessed_text",
              "type": "str",
              "description": "The preprocessed Quran text data."
            }
          ],
          "return_type": "dict"
        },
        {
          "name": "analyze_palindromes",
          "description": "Analyze palindromic structures within each verse of the Quran.\n    \n    This function identifies palindromic words and phrases at both the character level and word level.\n    It normalizes the text and parses each verse to extract Surah and Ayah information.\n    Detected palindromes are logged as potential secrets.\n    \n    Args:\n        quran_text (str): The preprocessed Quran text.\n    \n    Returns:\n        list: A list of tuples containing (surah, ayah, palindrome_text) for each detected palindrome.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_abjad_numerals",
          "description": "Perform Abjad numeral analysis on the Quran text.\n    \n    This function calculates the Abjad numerical sum for each verse based on a mapping of Arabic letters to their numerical values.\n    It identifies verses with sums that are multiples of significant numbers (e.g., 19 or 7) or whose sum is prime, and logs these findings as potential secrets.\n    \n    Args:\n        quran_text (str): The preprocessed Quran text.\n    \n    Returns:\n        list: A list of tuples containing (surah, ayah, abjad_sum, pattern_description) for each verse with a notable numerical pattern.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        },
        {
          "name": "analyze_semantic_symmetry",
          "description": "Analyze semantic symmetry (word overlap) between segments of each Surah.\n    \n    For each Surah, the function divides the content into two roughly equal halves.\n    For Surahs with only one verse that has enough words, the verse is split into two halves.\n    It calculates the overlap percentage between the two halves.\n    If the overlap exceeds a defined threshold, the finding is logged as a potential secret.\n    \n    Args:\n        quran_text (str): The preprocessed Quran text.\n    \n    Returns:\n        list: A list of tuples containing (surah, overlap_percentage, details) for each Surah with significant word overlap.",
          "parameters": [
            {
              "name": "quran_text",
              "type": "str",
              "description": "The preprocessed Quran text."
            }
          ],
          "return_type": "list"
        }
      ],
      "dependencies": [
        "collections",
        "datetime",
        "importlib.util",
        "src.logger",
        "src.text_preprocessor"
      ]
    },
    {
      "path": "src/logger.py",
      "language": "python",
      "description": "Module for logging analysis outputs of the Quran Secrets application. Provides functions to log secret findings, results, and bigram frequencies into a log file with timestamps.",
      "classes": [],
      "functions": [
        {
          "name": "log_secret_found",
          "description": "Logs a secret finding to the results.log file with a special tag and a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The secret message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_result",
          "description": "Logs a result message to the results.log file with a timestamp.",
          "parameters": [
            {
              "name": "message",
              "type": "str",
              "description": "The result message to log."
            }
          ],
          "return_type": "None"
        },
        {
          "name": "log_bigram_frequencies",
          "description": "Logs the top N most frequent bigrams to the results log file including header and frequency counts for the top N bigrams.",
          "parameters": [
            {
              "name": "bigram_frequencies",
              "type": "dict",
              "description": "A dictionary mapping bigram tuples to frequency counts."
            },
            {
              "name": "top_n",
              "type": "int",
              "description": "The number of top bigrams to log (default is 20)."
            }
          ],
          "return_type": "None"
        }
      ],
      "dependencies": []
    },
    {
      "path": "tests/__init__.py",
      "language": "Python",
      "description": "Initialization file for tests directory to mark it as a package and perform any necessary test setup.",
      "classes": [],
      "functions": [],
      "dependencies": []
    },
    {
      "path": "tests/test_file_reader.py",
      "language": "Python",
      "description": "Unit tests for the file_reader module that test reading an existing file and handling errors for non-existing files.",
      "classes": [
        {
          "name": "TestFileReader",
          "description": "Unit test class for testing the file_reader module including tests for reading existing files and error handling when files do not exist.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_read_existing_file",
              "description": "Test reading an existing file returns correct content.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_read_non_existing_file",
              "description": "Test that reading a non-existing file raises an IOError.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/file_reader.py"
      ]
    },
    {
      "path": "tests/test_text_preprocessor.py",
      "language": "Python",
      "description": "Unit tests for the text_preprocessor module testing the removal of diacritics and normalization of Arabic letters.",
      "classes": [
        {
          "name": "TestTextPreprocessor",
          "description": "Unit test class for the text_preprocessor module, ensuring proper functionality of diacritics removal and Arabic letter normalization.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "test_remove_diacritics",
              "description": "Test removal of Arabic diacritics from text.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_normalize_arabic_letters",
              "description": "Test normalization of specific Arabic letters in text.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/text_preprocessor.py"
      ]
    },
    {
      "path": "tests/test_analyzer.py",
      "language": "python",
      "description": "Unit tests for the analyzer module. Contains tests for verifying anomaly detection, word frequency analysis, Arabic root word analysis, bigram generation, palindrome detection, abjad numeral analysis, and semantic symmetry.",
      "classes": [
        {
          "name": "TestAnalyzer",
          "description": "Unit tests for functions in the analyzer module using the unittest framework.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Set up test environment and initial configurations.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_non_empty",
              "description": "Test that a non-empty text returns a simulated anomaly.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_empty",
              "description": "Test that an empty text returns no anomalies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_summary",
              "description": "Test that the word frequency analysis returns a proper summary and flagged list.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_word_frequency_with_flags",
              "description": "Test that the word frequency analysis flags unusual word frequencies.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_empty",
              "description": "Test Arabic root word analysis on empty text.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_root_words_sample",
              "description": "Test Arabic root word analysis on sample text with mocked CAMeL Tools analyzer.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_empty",
              "description": "Test that analyze_bigrams returns an empty dictionary for empty or insufficient tokenized text.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_bigrams_sample",
              "description": "Test analyze_bigrams with a sample tokenized text for correct bigram generation and frequency counting.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_palindromes_detects_palindrome",
              "description": "Test that analyze_palindromes detects palindromic words and phrases.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_abjad_numerals_detects_patterns",
              "description": "Test that analyze_abjad_numerals detects notable numerical patterns.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_analyze_semantic_symmetry_detects_symmetry",
              "description": "Test that analyze_semantic_symmetry detects significant word overlap.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestAnalyzer",
                  "description": "Instance of TestAnalyzer."
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "src/analyzer.py",
        "src/logger.py"
      ]
    },
    {
      "path": "tests/test_logger.py",
      "language": "Python",
      "description": "This file contains unit tests for the logger module. It tests the functionality of logging secret findings and general results. The tests use unittest framework with mocking to isolate the tests from actual file operations and datetime dependencies.",
      "classes": [
        {
          "name": "TestLogger",
          "description": "A test class that contains test cases for the logger module. It verifies that the logging functions correctly format and write messages to the log file.",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "Initializes the test environment by setting maxDiff to None to see full diff output in case of test failures.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_log_secret_found",
              "description": "Tests that the log_secret_found function correctly formats and writes a message about a potential secret to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            },
            {
              "name": "test_log_result",
              "description": "Tests that the log_result function correctly formats and writes a general result message to the log file. It mocks the datetime and file operations to verify the exact output.",
              "parameters": [
                {
                  "name": "self",
                  "type": "TestLogger",
                  "description": "Instance of the test class"
                },
                {
                  "name": "mock_datetime",
                  "type": "MagicMock",
                  "description": "Mocked datetime module to provide a fixed timestamp"
                },
                {
                  "name": "mock_file",
                  "type": "MagicMock",
                  "description": "Mocked file open function to capture file writes"
                }
              ],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "unittest",
        "os",
        "unittest.mock",
        "src.logger"
      ]
    },
    {
      "path": "tests/test_main.py",
      "language": "python",
      "description": "Integration test for the main module to execute end-to-end analysis. This test suite focuses on verifying the integration of the main functionalities of the application. It includes test cases to ensure the 'main' function executes correctly under different scenarios, such as with and without CAMeL Tools dependency, and that it produces the expected log outputs and analysis results. The tests cover core user flows and ensure the end-to-end functionality of the Quran analysis application.",
      "classes": [
        {
          "name": "TestMainIntegration",
          "description": "",
          "parents": [
            "unittest.TestCase"
          ],
          "methods": [
            {
              "name": "setUp",
              "description": "",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_fallback",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools fallback.",
              "parameters": [],
              "return_type": "None"
            },
            {
              "name": "test_main_integration_with_camel_tools",
              "description": "Test the full execution of main() function end-to-end with CAMeL Tools available.",
              "parameters": [],
              "return_type": "None"
            }
          ]
        }
      ],
      "functions": [],
      "dependencies": [
        "os",
        "unittest",
        "unittest.mock",
        "importlib.util",
        "src.main"
      ]
    },
    {
      "path": "data/quran-uthmani-min.txt",
      "language": "None",
      "description": "Text file containing the Quran text. This file is used as input for the analysis performed by the Quran Secrets application.",
      "classes": [],
      "functions": [],
      "dependencies": []
    }
  ]
}